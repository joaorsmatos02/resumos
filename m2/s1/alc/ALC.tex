\documentclass[10pt,a4paper]{report}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{lmodern}
\usepackage{amssymb}
\usepackage{verbatim}
\usepackage{float}
\usepackage{amsthm}
\usepackage{hyperref}
\title{\LARGE{Algorithms for Computational Logic} \\ \vspace{0.5cm} \normalsize{Summary}}
\date{}

\begin{document}
\maketitle
\tableofcontents

\chapter{SAT and Modeling with SAT}
\section{Cardinality Constraints}
In order to handle cardinality constraints we have two options: encode the cardinality constraints to CNF and use a SAT solver, or use a pseudo boolean (PB) solver.
\subsection{AtMost1}
\begin{itemize}
\item $\sum_{j=1}^n x_j = 1$ can be encoded with $\left(\sum_{j=1}^n x_j \leq 1\right) \land \left(\sum_{j=1}^n x_j \geq 1\right)$
\item $\sum_{j=1}^n x_j \geq 1$ can be encoded with $(x_1 \lor x_2 \lor ... \lor x_n)$
\item $\sum_{j=1}^n x_j \leq 1$ can be encoded with:
\begin{itemize}
\item Pairwise encoding
\item Sequential counter encoding
\item Bitwise encoding
\end{itemize}
\end{itemize}
\subsubsection{Sequential Counter}
In order to realize this encoding, we need to add new variables $s_i$ for the fact "there is a 1 on some position $1..i$":
$$
s_i \text{ is true if } \sum_{j=1}^i x_j \geq 1
$$
Encoding $\sum_{j=1}^n x_j \leq 1$ with sequential counter:
\begin{align*}
&(\neg x_1 \lor s_1) \land\\
&(\neg x_i \lor s_i), i \in 2..n-1 \land\\
&(\neg s_{i-1} \lor s_i), i \in 2..n-1 \land\\
&(\neg x_i \lor \neg s_{i-1}), i \in 2..n
\end{align*}
If $x_j = 1$, then all $s_i$ variables are assigned and all other $x$ variables must take value 0. There are $\mathcal{O}(n)$ clauses and $\mathcal{O}(n)$ auxiliary variables.
\subsubsection{Bitwise Encoding}
In bitwise encoding, we represent the constraint $\sum_{j=1}^n x_j \leq 1$ by encoding the index of the potential true variable in binary. For this, we add new auxiliary variables:
$$
v_0, ... v_r-1;\; r=\lceil \log n \rceil (\text{with } n > 1)
$$
Each variable $x_j$ is assigned a unique binary number that represents its index. Then, for each variable $x_j$ with binary index representation $i$, we create clauses that enforce the condition: 
\begin{itemize}
    \item If $x_j = 1$, assignment to $v_i$ variables must encode $j - 1$, and all other $x$ variables must take value 0
    \item If all $x_j = 0$, any assignment to $v_i$ variables is consistent
\end{itemize}
For example, $x_1 + x_2 + x_3 \leq 1$:\\
\begin{minipage}{0.4\textwidth} 
    \centering
    \begin{table}[H]
        \begin{tabular}{ccc}
              & $j-1$ & $v_1v_0$ \\ \cline{1-3}
        $x_1$ & 0     & 00   \\
        $x_2$ & 1     & 01  \\
        $x_3$ & 2     & 10   
        \end{tabular}
    \end{table}
\end{minipage}
\begin{minipage}{0.55\textwidth} 
    \begin{align*}
        &(\neg x_1 \lor \neg v_1) \land (\neg x_1 \lor \neg v_0)\\
        &(\neg x_2 \lor \neg v_1) \land (\neg x_2 \lor v_0)\\
        &(\neg x_3 \lor v_1) \land (\neg x_3 \lor \neg v_0)\\
    \end{align*}
\end{minipage}
There are $\mathcal{O}(n\log n)$ clauses and $\mathcal{O}(\log n)$ auxiliary variables

\subsection{General Cardinality Constraints}
Constraints of the form $\sum_{j=1}^n x_j \leq k$ or $\sum_{j=1}^n x_j \geq k$ can be added with:
\begin{itemize}
    \item Sequential Counters
    \item BDDs
    \item Sorting Networks
    \item Cardinality Networks
    \item Totalizer
\end{itemize}
\subsubsection{Sequential Counter Encoding}
For each variable $x_i$, create k additional variables $s_{i,j}$ that are used as counters:
\begin{itemize}
    \item $s_{i,j} = 1$ if at least $j$ variables $\{x_1 ... x_i\}$ are assigned value 1
    \item $s_{i,j} = 0$ if at most $j - 1$ variables $\{x_1 ... x_i\}$ are assigned value 1
\end{itemize}
Encoding:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{1.png}
\end{figure}
\subsubsection{Totalizer Encoding}
In this encoding we count in unary how many of the $n$ variables $(x_1 ... x_n)$ are assigned to 1. It can be visualized as a tree:
\begin{itemize}
    \item Each node is ($name$ : $variable$ : $sum$)
    \item Root node has the output variables $(o_1 ... o_n)$ that count how many variables are assigned to 1
    \item Literals are at the leaves
    \item Each node counts in unary how many leaves are assigned to 1 in its subtree
    \item Example: if $b_2 = 1$, then at least 2 of the leaves $(x_3, x_4, x_5)$ are
    assigned to 1
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{2.png}
\end{figure}
To encode $x_1 + x_2 + x_3 + x_4 + x_5 \leq 3$ just set $o_4=0$ and $o_5=0$.\\
Encoding:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{3.png}
\end{figure}
There are $\mathcal{O}(n\log n)$ new variables and $\mathcal{O}(n^2)$ new clauses

\section{Pseudo-Boolean Constraints}
The general form of these constraints is $\sum_{j=1}^n a_jx_j \leq b$
\subsection{Encodings}
\subsubsection{BDD Encoding}
BDDs can be used to encode pseudo-boolean constraints. For example, to encode $3x_1 + 3x_2 + x_3 \leq 3$, we can construct the following BDD and extract its ITE-based circuit:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{18.png}
\end{figure}
\subsubsection{Sequential Weighted Counter Encoding}
Assuming the general form $\sum_{i=1}^n w_ix_i \leq k$, where the weights are all non-negative:
\begin{itemize}
    \item For each variable $x_i$, create $k$ additional variables $s_{i,j}$ that are used as counters
    \begin{itemize}
        \item $s_{i,j} = 1$ if the weighted sum of the first $i$ variables $\{x_1 . . . x_i\}$ is at least $j$
        \item $s_{i,j} = 0$ if the weighted sum of the first $i$ variables $\{x_1 . . . x_i\}$ is at most $j-1$
    \end{itemize}
\end{itemize}
Encoding:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{19.png}
\end{figure}
\subsubsection{Generalized Totalizer Encoding}
The goal of GTE  is to account for the possible values of the left-hand side. It only considers the possible sums generated from the weights in the constraint. For example, in $2x_1 + 3x_2 + 3x_3 + 3x_4 \leq 5$ it is not possible for the weighted sum to have value 1, 4 or 7.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{20.png}
\end{figure}
\subsection{Pseudo-Boolean Optimization}
Suppose we must minimize $\sum_{j=1}^n c_jx_j$ subject to $\sum_{j=1}^n a_{ij}x_j \leq b_i \;\; \forall i \in \{1, ..., m\}, \forall j \in \{1, ..., n\}, x_j \in \{0, 1\}$. To translate this to MaxSAT we should:
\begin{itemize}
    \item Encode each pseudo-Boolean constraint into CNF. All clauses used in the encoding are hard
    \item For each term $c_jx_j$ in the objective function, add a soft clause $(\lnot x_j)$ with weight $c_j$
\end{itemize}
There are several ways of solving the optimization problem:
\begin{itemize}
    \item Translate into MaxSAT and use a Weighted MaxSAT algorithm
    \item Iterative Pseudo-Boolean solving
    \item Core-guided Pseudo-Boolean solving
    \item Branch-and-Bound Search
\end{itemize}
Given a PBO problem instance, where variables have an integer
domain, the Linear Programming Relaxation is the corresponding
linear program where the variable's integer constraints are relaxed
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{21.png}
\end{figure}
\subsubsection{Linear Programming Relaxation}
LPR is relevant since if can be solved quickly and if he relaxed linear program returns an optimal solution where all variables have integer value, then the solution of the relaxed linear program is also the optimal solution of the PBO problem. If the solution of the relaxed linear program is not integer for some variable, it still provides a lower bound on the optimal value of the PBO optimal solution
\subsubsection{Branch-and-Bound Search}
In the branch and bound algorithm we search by recursively dividing into smaller subproblems. It continuously uses LPR to get lower bounds (in case of minimization) and get candidade solutions.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{22.png}
\end{figure}
\subsection{Cutting Planes}
Cutting planes are used to further prune the space. Can be used to combine two constraints:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{23.png}
\end{figure}
For example:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{24.png}
\end{figure}
Rounding can also be applied:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{25.png}
\end{figure}
For example:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{26.png}
\end{figure}
And backtracking can also be applied:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{27.png}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{28.png}
\end{figure}


\section{SAT Algorithms}
\subsection{DPLL Solvers}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{4.png}
\end{figure}
\subsection{CDCL Solvers}
CDCL solvers extend DPLL solvers with clause learning and non-chronological backtracking, search restarts, lazy data structures, conflict-guided branching, etc.
\subsubsection{Clause Learning}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{5.png}
\end{figure}
And after backtracking:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{6.png}
\end{figure}
\subsubsection{Unique Implication Points}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{7.png}
\end{figure}
\subsubsection{Clause Minimization}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{8.png}
\end{figure}

\chapter{Optimization problems and SAT-Based Problem Solving}
A set of constraints is overconstrained if it is inconsistent. In a given an unsatisfiable formula, there may be several explanations for its unsatisfiability. The goal of MaxSAT is to find largest subset of clauses that is satisfiable.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{9.png}
\end{figure}

\section{MaxSAT Algorithms}
\subsection{Fu and Malik}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{10.png}
\end{figure}
\subsection{MSU3}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{11.png}
\end{figure}

\section{Minimal Unsatisfiable Subsets}
Given $\mathcal{F}$ unsatisfiable, $\mathcal{M} \subseteq \mathcal{F}$ is a MUS iff $\mathcal{M}$ is unsatisfiable and $\forall_{c \in \mathcal{M}}, \mathcal{M} \setminus \{c\}$ is satisfiable.
\subsection{Algorithms}
The following algorithms may be used to identify minimal unsatisfiable subsets.
\subsubsection{Deletion-Based}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{12.png}
\end{figure}
\subsubsection{Insertion-Based}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{13.png}
\end{figure}
\subsubsection{Dichotomic}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{14.png}
\end{figure}

\section{Minimal Correction Subsets}
$\mathcal{C} \subseteq \mathcal{F}$ is an MCS iff $\mathcal{F} \setminus \mathcal{C}$ is satisfiable and $\forall_{c \in \mathcal{C}}, \mathcal{F} \setminus (\mathcal{C} \setminus \{c\})$ is unsatisfiable.
\subsection{Algorithms}
The following algorithms may be used to identify minimal correction subsets.
\subsubsection{Basic Linear Search}
\begin{itemize}
    \item Let $\mathcal{S} \subseteq \mathcal{F}$, such that $\mathcal{S}\nvDash \bot$, initially $\mathcal{S} = \emptyset$
    \item Let $\mathcal{C} \subseteq \mathcal{F}$, such that $\forall_{c \in \mathcal{C}}, \mathcal{S} \cup \{c\} \vDash \bot $, initially $\mathcal{C} = \emptyset$
    \item At each iteration, analyze one clause of $c \in \mathcal{F} \setminus (\mathcal{S} \cup \mathcal{C})$:
    \begin{itemize}
        \item If $\mathcal{S} \cup \{c\} \vDash \bot$, then add $c$ to $\mathcal{C}$, i.e. $c$ is part of MCS
        \item If $\mathcal{S} \cup \{c\} \nvDash \bot$, then add $c$ to $\mathcal{C}$, i.e. $c$ is part of MCS
    \end{itemize}
\end{itemize}
There are $\mathcal{O}(m)$ calls to the oracle. An example:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{15.png}
\end{figure}
\subsubsection{Clause D}
\begin{itemize}
    \item Pick an assignment and let $\mathcal{S} \subseteq \mathcal{F}$ be the satisfied clauses and $\mathcal{U} \subseteq \mathcal{F}$ be the falsified clauses, with $\mathcal{F} = \mathcal{S} \cup \mathcal{U}$
    \item Repeat:
    \begin{itemize}
        \item Create clause $D = \cup_{l \in c, c \in \mathcal{U}} l$
        \item If $\mathcal{S} \cup \{D\} \vDash \bot$, then $\mathcal{U}$ is MCS: Report MCS and terminate
        \item If $\mathcal{S} \cup \{D\} \nvDash \bot$, then add to $\mathcal{S}$ the satisfied clauses in $\mathcal{U}$, remove from $\mathcal{U}$ the satisfied clauses and loop
    \end{itemize}
\end{itemize}
There are $\mathcal{O}(m-r)$ calls to the oracle, where $r$ is the size of the smallest MCS. An example:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.4]{16.png}
\end{figure}

\section{Duality Between MUSes and MCSes}
\begin{itemize}
    \item Let $\mathcal{S}$ be a finite set
    \item Let $\mathcal{F}$ be a set of subsets of $\mathcal{S}, \mathcal{F} \subseteq 2^\mathcal{S}$
    \item A hitting set $\mathcal{H} \subseteq \mathcal{S}$ is such that $\forall_{\mathcal{G} \in \mathcal{F}} \mathcal{H} \cap \mathcal{G} \neq \emptyset$
    \item $\mathcal{H}$ is (subset) minimal  if none of its subsets is a hitting set of $\mathcal{F}$
    \item $\mathcal{H}$ is cardinality minimal (or of minimum size) if there are no hitting sets of $\mathcal{F}$ with fewer elements
\end{itemize}
For example:
\begin{align*}
    &\mathcal{S} = \{1, 2, 3, 4, 5, 6, 7\}\\
    &\mathcal{F} = \{\{1, 2, 3\}, \{3, 4, 5\}, \{5, 6, 7\}\}\\
    &\mathcal{H}_1 = \{1, 2, 4, 6, 7\}\\
    &\mathcal{H}_1 = \{2, 4, 6\}\\
    &\mathcal{H}_1 = \{3, 7\}
\end{align*}
MUSes are minimal hitting sets of MCSes, and MCSes are minimal hitting sets of MUSes. En example:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{17.png}
\end{figure}
\subsection{MHS Approach for Solving MaxSAT}
The MaxSAT solution is a smallest MCS, and any MCS is a hitting set of all MUSes. This duality can be used to solve MaxSAT:
\begin{enumerate}
    \item Let $\mathcal{K}$ be a set of unsatisfiable cores (or MUSes)
    \item Find a minimum hitting set $\mathcal{H}$ of the set $\mathcal{K}$ of already computed cores (or MUSes)
    \item Check satisfiability of $\mathcal{F} \setminus \mathcal{H}$
    \begin{itemize}
        \item If satisfiable, then $\mathcal{H}$ is a smallest MCS; terminate and return $\mathcal{H}$
        \item Otherwise, compute core (or MUS) and add it to $\mathcal{K}$
    \end{itemize}
    \item Loop from 2
\end{enumerate}
\subsection{Enumeration}
\subsubsection{MCSes}
Generate and block:
\begin{enumerate}
    \item Extract MCS $\mathcal{C}$
    \item Block $\mathcal{C}$, i.e. at least one clause in $\mathcal{C}$ must be satisfied
    \item Loop from 1
\end{enumerate}
\subsubsection{MUSes}
The process for enumerating MUSes is different since we cannot block them: preventing a clause from being added to the MUS is infeasible. The only solution is explicit set enumeration. Compute all MCSes and then all MUSes:
\begin{itemize}
    \item Compute all MCSes using MCS enumerator
    \item Compute all minimal hitting sets of the MCSes
\end{itemize}

\chapter{Satisfiability Modulo Theories}
SMT refer to the determination of whether a logical formula can be satisfied given certain constraints or theories. There are eager and lazy approaches for SMT solving.
\section{Eager Approaches}
Eager approaches encode the problem into a CNF and solve it with a SAT solver (single SAT call).
\subsection{Finite Models with Booleans}
Finding a model of finite size $n$ can be encoded as SAT.
\subsubsection{Log-encoding}
In log-encoding, elements of the universe are represented by $k = \lceil \log_2 n\rceil$ boolean variables:
\begin{itemize}
    \item Equality: $(a_k, ..., a_0) = (b_k, ..., b_0) \rightsquigarrow \bigwedge_{i \in 0..k} (a_i \Leftrightarrow b_i)$
    \item Inequality: $(a_k, ..., a_0) < (b_k, ..., b_0) \rightsquigarrow (\lnot a_k \land b_k) \lor ((a_k \Leftrightarrow b_k) \land (a_{k-1}, ..., a_0) < (b_{k-1}, ..., b_0))$
    \item Other operations can be encoded, e.g. summation and multiplication by school method
\end{itemize}
\subsubsection{Unary-encoding}
In unary-encoding, elements are represented by $n$ boolean variables, with $a_i \Rightarrow a_{i-1}$ for $i \in 1..n$:
\begin{itemize}
    \item Equality: $(a_n, ..., a_0) = (b_n, ...m b_0) \rightsquigarrow \bigwedge_{i \in 0..n} (a_i \Leftrightarrow b_i)$
    \item Inequality: $(a_n, ..., a_0) < (b_n, ..., b_0) \rightsquigarrow \bigvee_{i \in 0..n} (\lnot a_i \land b_i)$
\end{itemize}
Log-encoding smaller but unary-encoding tends to give better behavior in SAT solvers.
\subsection{Small Model Properties}
In some theories, satisfiability can be encoded into finding a finite model. A formula with only equality and $n$ variables is satisfiable iff it has a model of at most size $n$.\\
\\
This is true seince for any larger model $A'$ we can construct $A'$ by considering only elements used to interpret the variables in the formula. For example, $(x_1 = x_2) \lor (x_1 = x_3) \land (x_3 \neq x_2)$ is decided by looking for a model up to size 3.
\subsubsection{Integer Difference Logic}
Let $s$ be the sum of absolute values of weights and $n$ number of variables. It is sufficient to look for a model with integers in $0..(s+n)$, since any solution can be shifted to it starts at 0. We can "compress" any solution while preserving the satisfiability of the same literals.
\subsection{Ackerman's Reduction}
When working with uninterpreted functions, for each application $f(\vec{a})$ introduce a fresh variable $f_a$ and for each pair of applications $f(\vec{a}), f(\vec{c})$ add the implication $\vec{a} = \vec{c} \Rightarrow f_{\vec{a}} = f_{\vec{c}}$. For example:
\begin{align*}
    &f(a) \neq f(c) \land (a = c \lor f(a) = c)\\
    &f_a \neq f_c \land (a = c \lor f_a = c) \land (a = c \Rightarrow f_a = f_c)
\end{align*}
We must also consider the sub-terms:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{29.png}
\end{figure}

\section{Lazy Approaches}
Lazy approaches use SAT for the boolean structure and a theory solver for conjunctions of literals (multiple SAT calls). The following is needed:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{30.png}
\end{figure}
And the algorithm is as follows:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{31.png}
\end{figure}
\subsection{Theory Solver}
The theory solver checks models from the SAT solver within the theory.
\subsubsection{Congruence Closure}
Congruence closure is used for equality:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{32.png}
\end{figure}
For example:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{33.png}
\end{figure}
\subsubsection{Integer Difference Logic}
IDL is used on integer variables to make a conjunction of linear inequalities of the form $x_i - x_j \leq k$. The algorithm is as follows:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{34.png}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{35.png}
\end{figure}
For example:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{36.png}
\end{figure}

\section{Theories}
\subsection{Real Linear Arithmetic}
RLA is a theory in SMT that deals with formulas involving linear inequalities over real numbers. An RLA formula may include constraints like $a_x + b_y \leq c$, where $a$, $b$, and $c$ are constants, and $x$ and $y$ are real-valued variables.
\subsubsection{The Simplex Method}
The Simplex Method is a well-known algorithm from linear programming used for solving systems of linear inequalities, especially for real-valued variables. It works in three phases:
\begin{itemize}
    \item Formulation: The system of inequalities is converted into an objective function subject to constraints, where the goal is to either maximize or minimize a certain variable.
    \item Pivoting: The algorithm iteratively improves feasible solutions by "pivoting" on certain variables, adjusting values while keeping all constraints satisfied.
    \item Termination: It terminates when either a feasible solution is found (satisfying the constraints) or it determines that the system is infeasible.
\end{itemize}
\subsubsection{Fourier-Motzkin}
FM is an anternative to simplex. The idea is if $A \leq x$ and $x \leq B$, then $A \leq B$. Elimination by forcing all bounds to be nonempty:
$$
\left(\bigwedge_i A_i \leq x \land \bigwedge_j x\leq B_j \right) \Leftrightarrow \bigwedge_{i,j} A_i \leq B_j
$$
It works in two phases:
\begin{itemize}
    \item Phase 1: eliminate equalities
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{37.png}
    \end{figure}
    \item Phase 2: Variable Elimination
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{38.png}
    \end{figure}
\end{itemize}
For example:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{39.png}
\end{figure}
\subsection{Combining Theories}
Until now we have assumed there is a single theory, but in practice it is important to combine theories. To do so, we can use the Nelson-Oppen method (under certain conditions), use lazy solving and let the theory solvers communicate through equality. It works in two steps:
\begin{itemize}
    \item First step: puriﬁcation
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{40.png}
    \end{figure}
    \item Second step: guess and check
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{41.png}
    \end{figure}
\end{itemize}

\chapter{Answer Set Programming}
ASP is a declarative problem solving paradigm. The problems are specified using rules similar to logic programming, with convenient extensions.
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{42.png}
\end{figure}
\section{Answer Sets}
The process to compute an answer set is as follows:
\begin{itemize}
    \item First, ground the program, i.e., substitute specific values for variables in the rules
    \item In positive programs - simpler case: no negation
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{43.png}
    \end{figure}
    \item In programs with negation - consider a guess $S$ - compute the reduct which has no negations
    \begin{itemize}
        \item If the answer set of the reduct (positive program) is exactly $S$ then $S$ is an answer set
    \end{itemize}
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{44.png}
    \end{figure}
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{45.png}
    \end{figure}
\end{itemize}
An example:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{46.png}
\end{figure}
\section{Extensions}
Many extensions can be implemented into ASP (definition of answer set has to be extended), for example:
\begin{itemize}
    \item Arithmetic: rules may contain symbols for arithmetic operations and comparisons
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{47.png}
    \end{figure}
    \item Disjunctive rules: the head of a rule may be a disjunction of several atoms (often separated by bars or semicolons), rather than a single atom
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{48.png}
    \end{figure}
    \item Choice rules: enclosing the list of atoms in the head in curly braces represents the "choice" construct; choose in all possible ways which atoms from the list will be included in the answer set
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{49.png}
    \end{figure}
    One may specify bounds on the number of atoms that are included: the lower bound is shown to the left of the expression in braces, and the upper bound to the right
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{50.png}
    \end{figure}
    \item Constraints: disjunctive rule that has 0 disjuncts in the head, so that it starts with the symbol :-
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{51.png}
    \end{figure}
    \item Classical negation: the "classical negation" sign (–) should be distinguished from the negation as failure symbol (not)
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.5]{52.png}
    \end{figure}
\end{itemize}

\end{document}
